{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task #1: Get info Box (store in Python dictionary)\n",
    "\n",
    "### Import necessary libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(url='https://en.wikipedia.org/wiki/WALL-E')\n",
    "# Convert to a beautiful soup object\n",
    "soup = bs(req.content)\n",
    "\n",
    "# Print out the HTML\n",
    "contents = soup.prettify()\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_box = soup.find(class_='infobox vevent')\n",
    "info_rows = info_box.find_all('tr')\n",
    "for row in info_rows:\n",
    "    print(row.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_value(row_data):\n",
    "    if row_data.find('li'):\n",
    "        return [li.get_text('|', strip=True).replace('\\xa0', ' ') for li in row_data.find_all('li')]\n",
    "    else:\n",
    "        return row_data.get_text(' ', strip=True).replace('\\xa0', ' ')\n",
    "\n",
    "movie_info: dict = {}\n",
    "\n",
    "for index, row in enumerate(info_rows):\n",
    "    if index == 0:\n",
    "        movie_info['title'] = row.find('th').get_text('|', strip=True)\n",
    "    elif index == 1:\n",
    "        continue\n",
    "    else:\n",
    "        header = row.find('th')\n",
    "        if header:\n",
    "            content_key = row.find('th').get_text('|', strip=True)\n",
    "            content_value = get_content_value(row.find('td'))\n",
    "            movie_info[content_key] = content_value\n",
    "\n",
    "movie_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task #2: Get info box for all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url='https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films')\n",
    "\n",
    "# Convert to a beautiful soup object\n",
    "soup = bs(r.content)\n",
    "\n",
    "contents = soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = soup.select('.wikitable.sortable i a')\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    \" \", strip=True:\n",
    "    \" \" - каким образом разделить объединенные строки\n",
    "    strip=True - удалить пробелы в начале и конце строк\n",
    "    Напримре: Productioncompany --> Production company\n",
    "'''\n",
    "def get_content_value(row_data):\n",
    "    if row_data.find('li'):\n",
    "        return [li.get_text(' ', strip=True).replace('\\xa0', ' ') for li in row_data.find_all('li')]\n",
    "    \n",
    "    # Данный elif находит тег <br>, из-за которого не получалось на выходе получить лист\n",
    "    # Например, без данного elif мы получали: 'Starring': 'Fess Parker Jeffrey Hunter John Lupton Jeff York Slim Pickens',\n",
    "    # После добавления данного elif получили: 'Starring': ['Fess Parker', 'Jeffrey Hunter', 'John Lupton', 'Jeff York', 'Slim Pickens']\n",
    "    elif row_data.find('br'):\n",
    "        return [text for text in row_data.stripped_strings]\n",
    "    else:\n",
    "        return row_data.get_text(' ', strip=True).replace('\\xa0', ' ')\n",
    "\n",
    "\n",
    "# Функция очищает тэги <sup> - который отображает текст в виде верхнего индекса\n",
    "# и <span> - который отображает дату в формате \"yyyy.mm.dd\"\n",
    "def clean_tags(soup):\n",
    "    for tag in soup.find_all(['sup', 'span']):\n",
    "        tag.decompose()\n",
    "\n",
    "\n",
    "def get_info_box(relative_path, url: str) -> dict:\n",
    "    req = requests.get(url=url)\n",
    "    # Convert to a beautiful soup object\n",
    "    soup = bs(req.content, 'html.parser')  # Указываем парсер 'html.parser'\n",
    "\n",
    "    info_box = soup.find(class_='infobox vevent')\n",
    "    if not info_box:\n",
    "        return {} # Возвращаем пустой словарь, если инфобокс не найден\n",
    "    \n",
    "    info_rows = info_box.find_all('tr')\n",
    "    \n",
    "    clean_tags(soup=soup)\n",
    "\n",
    "    movie_info = {}\n",
    "\n",
    "    for index, row in enumerate(info_rows):\n",
    "        if index == 0: # Извлекаем название фильма\n",
    "            movie_info['URL'] = relative_path\n",
    "            movie_info['title'] = row.find('th').get_text(' ', strip=True)\n",
    "            # movie_info['link'] = [a['href'] for a in row.find_all('a', href=True)]\n",
    "            \n",
    "        elif index == 1:  # Пропускаем вторую строку, если нужно\n",
    "            continue\n",
    "        else:\n",
    "            header = row.find('th')\n",
    "            # print(header)\n",
    "            if header:\n",
    "                content_key = row.find('th').get_text(' ', strip=True)\n",
    "                content_value = get_content_value(row.find('td'))\n",
    "                movie_info[content_key] = content_value\n",
    "\n",
    "    return movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "req = requests.get(url='https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films')\n",
    "\n",
    "# Convert to a beautiful soup object\n",
    "soup = bs(req.content, 'html.parser')\n",
    "\n",
    "base_path = 'https://en.wikipedia.org/'\n",
    "\n",
    "movies = soup.select('.wikitable.sortable i a')\n",
    "\n",
    "\n",
    "movie_info_list: list = []\n",
    "\n",
    "for index, movie in enumerate(movies):\n",
    "    # endpoint = soup.select('h2')[0].get_text()\n",
    "    # if endpoint == 'Upcoming':\n",
    "    #     break\n",
    "\n",
    "    if index % 10 == 0:\n",
    "        print(index)\n",
    "\n",
    "    try:\n",
    "        relative_path = movie['href']\n",
    "        full_path = base_path + relative_path\n",
    "        title = movie['title']\n",
    "\n",
    "        # В список добавляем словарь, который возвращает функция get_info_box\n",
    "        movie_info_list.append(get_info_box(relative_path, full_path))\n",
    "    except Exception as e:\n",
    "        print(movie.get_text())\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info_box(url='https://en.wikipedia.org/wiki/Snow_White_and_the_Seven_Dwarfs_(1937_film)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_info_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Reload Movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранить данные в JSON формат\n",
    "import json\n",
    "def save_data(title, data):\n",
    "    with open(file=title, mode='w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data('disney_data.json', movie_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить данные из JSON формата\n",
    "import json\n",
    "def load_data(title):\n",
    "    with open(title, mode='r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info_list = load_data(title='disney_data.json')\n",
    "# df = pd.DataFrame(movie_info_list)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task #3: Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtasks\n",
    "- ~~Clean up references (remove [1] [2] etc)~~ функция clean_tags выше\n",
    "- Convert running time into an integer\n",
    "- Convert dates into datetime object\n",
    "- ~~Split up the long strings~~\n",
    "- Convert Budget and Box office to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up the long strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movie_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[movie.get('Running time', 'N/A') for movie in movie_info_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minutes_to_integer(running_time):\n",
    "    if running_time == 'N/A':\n",
    "        return None\n",
    "    elif '\\n' not in running_time:\n",
    "        if isinstance(running_time, list):\n",
    "            return int(running_time[0].split(' ')[0])\n",
    "        else:\n",
    "            return int(running_time.split(' ')[0])\n",
    "    else:\n",
    "        if isinstance(running_time, list):\n",
    "            return int(running_time[0].split('\\n')[0])\n",
    "        else:\n",
    "            return int(running_time.split('\\n')[0])\n",
    "\n",
    "for movie in movie_info_list:\n",
    "    movie['Running time (int)'] = minutes_to_integer(movie.get('Running time', 'N/A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info_list[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(movie_info_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Release date'] = pd.to_datetime(df['Release date'][0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# искать символ переноса строки ('\\n') по всем столбцам с помощью .applymap():\n",
    "rows_with_newline = df[df.map(lambda x: '\\n' in str(x)).any(axis=1)]\n",
    "rows_with_newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
